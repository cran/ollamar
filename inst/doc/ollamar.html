<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Using ollamar</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Using ollamar</h1>



<p>ollamar is the easiest way to integrate R with <a href="https://ollama.com/">Ollama</a>, which lets you run language
models locally on your own machine.</p>
<div id="installation" class="section level2">
<h2>Installation</h2>
<ol style="list-style-type: decimal">
<li>Download and install the <a href="https://ollama.com">Ollama</a>
app.</li>
</ol>
<ul>
<li><a href="https://ollama.com/download/Ollama-darwin.zip">macOS</a></li>
<li><a href="https://ollama.com/download/OllamaSetup.exe">Windows
preview</a></li>
<li>Linux:
<code>curl -fsSL https://ollama.com/install.sh | sh</code></li>
<li><a href="https://hub.docker.com/r/ollama/ollama">Docker
image</a></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>Open/launch the Ollama app to start the local server.</p></li>
<li><p>Install either the stable or latest/development version of
<code>ollamar</code>.</p></li>
</ol>
<p>Stable version:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ollamar&quot;</span>)</span></code></pre></div>
<p>For the latest/development version with more features/bug fixes (see
latest changes <a href="https://hauselin.github.io/ollama-r/news/index.html">here</a>),
you can install it from GitHub using the <code>install_github</code>
function from the <code>remotes</code> library. If it doesn’t work or
you don’t have <code>remotes</code> library, please run
<code>install.packages(&quot;remotes&quot;)</code> in R or RStudio before running
the code below.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># install.packages(&quot;remotes&quot;)  # run this line if you don&#39;t have the remotes library</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>remotes<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;hauselin/ollamar&quot;</span>)</span></code></pre></div>
</div>
<div id="usage" class="section level2">
<h2>Usage</h2>
<p><code>ollamar</code> uses the <a href="https://httr2.r-lib.org/index.html"><code>httr2</code> library</a>
to make HTTP requests to the Ollama server, so many functions in this
library returns an <code>httr2_response</code> object by default. If the
response object says <code>Status: 200 OK</code>, then the request was
successful.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">library</span>(ollamar)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="fu">test_connection</span>()  <span class="co"># test connection to Ollama server</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># if you see &quot;Ollama local server not running or wrong server,&quot; Ollama app/server isn&#39;t running</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co"># generate a response/text based on a prompt; returns an httr2 response by default</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;tell me a 5-word story&quot;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>resp</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&#39; interpret httr2 response object</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&#39; &lt;httr2_response&gt;</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&#39; Status: 200 OK  # if successful, status code should be 200 OK</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&#39; Content-Type: application/json</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&#39; Body: In memory (414 bytes)</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co"># get just the text from the response object</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;text&quot;</span>)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co"># get the text as a tibble dataframe</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;df&quot;</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co"># alternatively, specify the output type when calling the function initially</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>txt <span class="ot">&lt;-</span> <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;tell me a 5-word story&quot;</span>, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="co"># list available models (models you&#39;ve pulled/downloaded)</span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a><span class="fu">list_models</span>()</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>                        name    size parameter_size quantization_level            modified</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a><span class="dv">1</span>               codegemma<span class="sc">:</span><span class="dv">7</span>b    <span class="dv">5</span> GB             <span class="dv">9</span>B               Q4_0 <span class="dv">2024-07-27</span>T23<span class="sc">:</span><span class="dv">44</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a><span class="dv">2</span>            llama3<span class="fl">.1</span><span class="sc">:</span>latest  <span class="fl">4.7</span> GB           <span class="fl">8.0</span>B               Q4_0 <span class="dv">2024-07-31</span>T07<span class="sc">:</span><span class="dv">44</span><span class="sc">:</span><span class="dv">33</span></span></code></pre></div>
<div id="pulldownload-model" class="section level3">
<h3>Pull/download model</h3>
<p>Download a model from the ollama library (see <a href="https://github.com/ollama/ollama/blob/main/docs/api.md#pull-a-model">API
doc</a>). For the list of models you can pull/download, see <a href="https://ollama.com/library">Ollama library</a>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">pull</span>(<span class="st">&quot;llama3.1&quot;</span>)  <span class="co"># download a model (equivalent bash code: ollama run llama3.1)</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">list_models</span>()  <span class="co"># verify you&#39;ve pulled/downloaded the model</span></span></code></pre></div>
</div>
<div id="delete-model" class="section level3">
<h3>Delete model</h3>
<p>Delete a model and its data (see <a href="https://github.com/ollama/ollama/blob/main/docs/api.md#delete-a-model">API
doc</a>). You can see what models you’ve downloaded with
<code>list_models()</code>. To download a model, specify the name of the
model.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">list_models</span>()  <span class="co"># see the models you&#39;ve pulled/downloaded</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">delete</span>(<span class="st">&quot;all-minilm:latest&quot;</span>)  <span class="co"># returns a httr2 response object</span></span></code></pre></div>
</div>
<div id="generate-completion" class="section level3">
<h3>Generate completion</h3>
<p>Generate a response for a given prompt (see <a href="https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion">API
doc</a>).</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Tomorrow is a...&quot;</span>)  <span class="co"># return httr2 response object by default</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>resp</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;text&quot;</span>)  <span class="co"># process the response to return text/vector output</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Tomorrow is a...&quot;</span>, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>)  <span class="co"># directly return text/vector output</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Tomorrow is a...&quot;</span>, <span class="at">stream =</span> <span class="cn">TRUE</span>)  <span class="co"># return httr2 response object and stream output</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Tomorrow is a...&quot;</span>, <span class="at">output =</span> <span class="st">&quot;df&quot;</span>, <span class="at">stream =</span> <span class="cn">TRUE</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co"># image prompt</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co"># use a vision/multi-modal model</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="fu">generate</span>(<span class="st">&quot;benzie/llava-phi-3&quot;</span>, <span class="st">&quot;What is in the image?&quot;</span>, <span class="at">images =</span> <span class="st">&quot;image.png&quot;</span>, <span class="at">output =</span> <span class="st">&#39;text&#39;</span>)</span></code></pre></div>
</div>
<div id="chat" class="section level3">
<h3>Chat</h3>
<p>Generate the next message in a chat/conversation.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;what is the capital of australia&quot;</span>)  <span class="co"># default role is user</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages)  <span class="co"># default returns httr2 response object</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>resp  <span class="co"># &lt;httr2_response&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;text&quot;</span>)  <span class="co"># process the response to return text/vector output</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co"># specify output type when calling the function</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>)  <span class="co"># text vector</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;df&quot;</span>)  <span class="co"># data frame/tibble</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;jsonlist&quot;</span>)  <span class="co"># list</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;raw&quot;</span>)  <span class="co"># raw string</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">stream =</span> <span class="cn">TRUE</span>)  <span class="co"># stream output and return httr2 response object</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co"># create chat history</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_messages</span>(</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;end all your sentences with !!!&quot;</span>, <span class="at">role =</span> <span class="st">&quot;system&quot;</span>),</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;Hello!&quot;</span>),  <span class="co"># default role is user</span></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;Hi, how can I help you?!!!&quot;</span>, <span class="at">role =</span> <span class="st">&quot;assistant&quot;</span>),</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;What is the capital of Australia?&quot;</span>),</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;Canberra!!!&quot;</span>, <span class="at">role =</span> <span class="st">&quot;assistant&quot;</span>),</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;what is your name?&quot;</span>)</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>)</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>))  <span class="co"># print the formatted output</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a><span class="co"># image prompt</span></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;What is in the image?&quot;</span>, <span class="at">images =</span> <span class="st">&quot;image.png&quot;</span>)</span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a><span class="co"># use a vision/multi-modal model</span></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;benzie/llava-phi-3&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>)</span></code></pre></div>
<div id="stream-responses" class="section level4">
<h4>Stream responses</h4>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;Tell me a 1-paragraph story.&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># use &quot;llama3.1&quot; model, provide list of messages, return text/vector output, and stream the output</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;text&quot;</span>, <span class="at">stream =</span> <span class="cn">TRUE</span>)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co"># chat(model = &quot;llama3.1&quot;, messages = messages, output = &quot;text&quot;, stream = TRUE)  # same as above</span></span></code></pre></div>
</div>
<div id="format-messages-for-chat" class="section level4">
<h4>Format messages for chat</h4>
<p>Internally, messages are represented as a <code>list</code> of many
distinct <code>list</code> messages. Each list/message object has two
elements: <code>role</code> (can be <code>&quot;user&quot;</code> or
<code>&quot;assistant&quot;</code> or <code>&quot;system&quot;</code>) and
<code>content</code> (the message text). The example below shows how the
messages/lists are presented.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">list</span>(  <span class="co"># main list containing all the messages</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">role =</span> <span class="st">&quot;user&quot;</span>, <span class="at">content =</span> <span class="st">&quot;Hello!&quot;</span>),  <span class="co"># first message as a list</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">role =</span> <span class="st">&quot;assistant&quot;</span>, <span class="at">content =</span> <span class="st">&quot;Hi! How are you?&quot;</span>)  <span class="co"># second message as a list</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>)</span></code></pre></div>
<p>To simplify the process of creating and managing messages,
<code>ollamar</code> provides functions to format and prepare messages
for the <code>chat()</code> function. These functions also work with
other APIs or LLM providers like OpenAI and Anthropic.</p>
<ul>
<li><code>create_messages()</code>: create messages to build a chat
history</li>
<li><code>create_message()</code> creates a chat history with a single
message</li>
<li><code>append_message()</code> adds a new message to the end of the
existing messages</li>
<li><code>prepend_message()</code> adds a new message to the beginning
of the existing messages</li>
<li><code>insert_message()</code> inserts a new message at a specific
index in the existing messages
<ul>
<li>by default, it inserts the message at the -1 (final) position</li>
</ul></li>
<li><code>delete_message()</code> delete a message at a specific index
in the existing messages
<ul>
<li>positive and negative indices/positions are supported</li>
<li>if there are 5 messages, the positions are 1 (-5), 2 (-4), 3 (-3), 4
(-2), 5 (-1)</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># create a chat history with one message</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="at">content =</span> <span class="st">&quot;Hi! How are you? (1ST MESSAGE)&quot;</span>, <span class="at">role =</span> <span class="st">&quot;assistant&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co"># or simply, messages &lt;- create_message(&quot;Hi! How are you?&quot;, &quot;assistant&quot;)</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>messages[[<span class="dv">1</span>]]  <span class="co"># get 1st message</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co"># append (add to the end) a new message to the existing messages</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">append_message</span>(<span class="st">&quot;I&#39;m good. How are you? (2ND MESSAGE)&quot;</span>, <span class="st">&quot;user&quot;</span>, messages)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>messages[[<span class="dv">1</span>]]  <span class="co"># get 1st message</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>messages[[<span class="dv">2</span>]]  <span class="co"># get 2nd message (newly added message)</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># prepend (add to the beginning) a new message to the existing messages</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">prepend_message</span>(<span class="st">&quot;I&#39;m good. How are you? (0TH MESSAGE)&quot;</span>, <span class="st">&quot;user&quot;</span>, messages)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>messages[[<span class="dv">1</span>]]  <span class="co"># get 0th message (newly added message)</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>messages[[<span class="dv">2</span>]]  <span class="co"># get 1st message</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>messages[[<span class="dv">3</span>]]  <span class="co"># get 2nd message</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># insert a new message at a specific index/position (2nd position in the example below)</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co"># by default, the message is inserted at the end of the existing messages (position -1 is the end/default)</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">insert_message</span>(<span class="st">&quot;I&#39;m good. How are you? (BETWEEN 0 and 1 MESSAGE)&quot;</span>, <span class="st">&quot;user&quot;</span>, messages, <span class="dv">2</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>messages[[<span class="dv">1</span>]]  <span class="co"># get 0th message</span></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>messages[[<span class="dv">2</span>]]  <span class="co"># get between 0 and 1 message (newly added message)</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>messages[[<span class="dv">3</span>]]  <span class="co"># get 1st message</span></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>messages[[<span class="dv">4</span>]]  <span class="co"># get 2nd message</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a><span class="co"># delete a message at a specific index/position (2nd position in the example below)</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">delete_message</span>(messages, <span class="dv">2</span>)</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a><span class="co"># create a chat history with multiple messages</span></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_messages</span>(</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;You&#39;re a knowledgeable tour guide.&quot;</span>, <span class="at">role =</span> <span class="st">&quot;system&quot;</span>),</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;What is the capital of Australia?&quot;</span>)  <span class="co"># default role is user</span></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>)</span></code></pre></div>
<p>You can convert <code>data.frame</code>, <code>tibble</code> or
<code>data.table</code> objects to <code>list()</code> of messages and
vice versa with functions from base R or other popular libraries.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># create a list of messages</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>messages <span class="ot">&lt;-</span> <span class="fu">create_messages</span>(</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;You&#39;re a knowledgeable tour guide.&quot;</span>, <span class="at">role =</span> <span class="st">&quot;system&quot;</span>),</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  <span class="fu">create_message</span>(<span class="st">&quot;What is the capital of Australia?&quot;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co"># convert to dataframe</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(messages)  <span class="co"># with dplyr library</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>df <span class="ot">&lt;-</span> data.table<span class="sc">::</span><span class="fu">rbindlist</span>(messages)  <span class="co"># with data.table library</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co"># convert dataframe to list with apply, purrr functions</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="fu">apply</span>(df, <span class="dv">1</span>, as.list)  <span class="co"># convert each row to a list with base R apply</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>purrr<span class="sc">::</span><span class="fu">transpose</span>(df)  <span class="co"># with purrr library</span></span></code></pre></div>
</div>
</div>
<div id="embeddings" class="section level3">
<h3>Embeddings</h3>
<p>Get the vector embedding of some prompt/text (see <a href="https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings">API
doc</a>). By default, the embeddings are normalized to length 1, which
means the following:</p>
<ul>
<li>cosine similarity can be computed slightly faster using just a dot
product</li>
<li>cosine similarity and Euclidean distance will result in the
identical rankings</li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hello, how are you?&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="co"># don&#39;t normalize embeddings</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hello, how are you?&quot;</span>, <span class="at">normalize =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># get embeddings for similar prompts</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>e1 <span class="ot">&lt;-</span> <span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hello, how are you?&quot;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>e2 <span class="ot">&lt;-</span> <span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hi, how are you?&quot;</span>)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co"># compute cosine similarity</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="fu">sum</span>(e1 <span class="sc">*</span> e2)  <span class="co"># not equals to 1</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="fu">sum</span>(e1 <span class="sc">*</span> e1)  <span class="co"># 1 (identical vectors/embeddings)</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co"># non-normalized embeddings</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>e3 <span class="ot">&lt;-</span> <span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hello, how are you?&quot;</span>, <span class="at">normalize =</span> <span class="cn">FALSE</span>)</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>e4 <span class="ot">&lt;-</span> <span class="fu">embed</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;Hi, how are you?&quot;</span>, <span class="at">normalize =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
</div>
<div id="parse-httr2_response-objects-with-resp_process" class="section level3">
<h3>Parse <code>httr2_response</code> objects with
<code>resp_process()</code></h3>
<p><code>ollamar</code> uses the <a href="https://httr2.r-lib.org/index.html"><code>httr2</code> library</a>
to make HTTP requests to the Ollama server, so many functions in this
library returns an <code>httr2_response</code> object by default.</p>
<p>You can either parse the output with <code>resp_process()</code> or
use the <code>output</code> parameter in the function to specify the
output format. Generally, the <code>output</code> parameter can be one
of <code>&quot;df&quot;</code>, <code>&quot;jsonlist&quot;</code>, <code>&quot;raw&quot;</code>,
<code>&quot;resp&quot;</code>, or <code>&quot;text&quot;</code>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">list_models</span>(<span class="at">output =</span> <span class="st">&quot;resp&quot;</span>)  <span class="co"># returns a httr2 response object</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co"># &lt;httr2_response&gt;</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="co"># Status: 200 OK</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># Content-Type: application/json</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co"># process the httr2 response object with the resp_process() function</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;df&quot;</span>)</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># or list_models(output = &quot;df&quot;)</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;jsonlist&quot;</span>)  <span class="co"># list</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co"># or list_models(output = &quot;jsonlist&quot;)</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;raw&quot;</span>)  <span class="co"># raw string</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co"># or list_models(output = &quot;raw&quot;)</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;resp&quot;</span>)  <span class="co"># returns the input httr2 response object</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co"># or list_models() or list_models(&quot;resp&quot;)</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="fu">resp_process</span>(resp, <span class="st">&quot;text&quot;</span>)  <span class="co"># text vector</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co"># or list_models(&quot;text&quot;)</span></span></code></pre></div>
</div>
</div>
<div id="advanced-usage" class="section level2">
<h2>Advanced usage</h2>
<div id="tool-calling" class="section level3">
<h3>Tool calling</h3>
<p>You can use <a href="https://ollama.com/blog/tool-support">tool
calling</a> with the <code>chat()</code> function with certain models
such as Llama3.1. See also <a href="https://github.com/ollama/ollama-python/blob/main/examples/tools.py">Python
examples</a>.</p>
<p>First, define your tools as functions. Two example functions are
shown below.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>add_two_numbers <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="fu">return</span>(x <span class="sc">+</span> y)</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>}</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>multiply_two_numbers <span class="ot">&lt;-</span> <span class="cf">function</span>(a, b) {</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>  <span class="fu">return</span>(a <span class="sc">*</span> b)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>}</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co"># each tool needs to be in a list</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>tool1 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;function&quot;</span>,</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>              <span class="st">&quot;function&quot;</span> <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>                <span class="at">name =</span> <span class="st">&quot;add_two_numbers&quot;</span>,  <span class="co"># function name</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>                <span class="at">description =</span> <span class="st">&quot;add two numbers&quot;</span>,</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>                <span class="at">parameters =</span> <span class="fu">list</span>(</span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">&quot;object&quot;</span>,</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>                  <span class="at">required =</span> <span class="fu">list</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>),  <span class="co"># function parameters</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>                  <span class="at">properties =</span> <span class="fu">list</span>(</span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>                    <span class="at">x =</span> <span class="fu">list</span>(<span class="at">class =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">description =</span> <span class="st">&quot;first number&quot;</span>),</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>                    <span class="at">y =</span> <span class="fu">list</span>(<span class="at">class =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">description =</span> <span class="st">&quot;second number&quot;</span>)))</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a>                )</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a>              )</span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a>tool2 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;function&quot;</span>,</span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a>              <span class="st">&quot;function&quot;</span> <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a>                <span class="at">name =</span> <span class="st">&quot;multiply_two_numbers&quot;</span>,  <span class="co"># function name</span></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a>                <span class="at">description =</span> <span class="st">&quot;multiply two numbers&quot;</span>,</span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a>                <span class="at">parameters =</span> <span class="fu">list</span>(</span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">&quot;object&quot;</span>,</span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a>                  <span class="at">required =</span> <span class="fu">list</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>),  <span class="co"># function parameters</span></span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a>                  <span class="at">properties =</span> <span class="fu">list</span>(</span>
<span id="cb15-31"><a href="#cb15-31" tabindex="-1"></a>                    <span class="at">x =</span> <span class="fu">list</span>(<span class="at">class =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">description =</span> <span class="st">&quot;first number&quot;</span>),</span>
<span id="cb15-32"><a href="#cb15-32" tabindex="-1"></a>                    <span class="at">y =</span> <span class="fu">list</span>(<span class="at">class =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">description =</span> <span class="st">&quot;second number&quot;</span>)))</span>
<span id="cb15-33"><a href="#cb15-33" tabindex="-1"></a>                )</span>
<span id="cb15-34"><a href="#cb15-34" tabindex="-1"></a>              )</span></code></pre></div>
<p>Then call the <code>chat()</code> function with the
<code>tools</code> parameter set to a list of your tools. Pass in a
single tool.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>msg <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;what is three plus one?&quot;</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, msg, <span class="at">tools =</span> <span class="fu">list</span>(tool1), <span class="at">output =</span> <span class="st">&quot;tools&quot;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>tool <span class="ot">&lt;-</span> resp[[<span class="dv">1</span>]]  <span class="co"># get the first tool/function</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co"># call the tool function with arguments: add_two_numbers(3, 1)</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="fu">do.call</span>(tool<span class="sc">$</span>name, tool<span class="sc">$</span>arguments)</span></code></pre></div>
<p>Pass in multiple tools. The model will pick the best tool to use
based on the context of the message.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>msg <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;what is three multiplied by four?&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, msg, <span class="at">tools =</span> <span class="fu">list</span>(tool1, tool2), <span class="at">output =</span> <span class="st">&quot;tools&quot;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>tool <span class="ot">&lt;-</span> resp[[<span class="dv">1</span>]]  <span class="co"># get the first tool/function</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="co"># call the tool function with arguments: multiply_two_numbers(3, 4)</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="fu">do.call</span>(tool<span class="sc">$</span>name, tool<span class="sc">$</span>arguments)</span></code></pre></div>
<p>Pass in multiple tools and get the model to use multiple tools. Note
that LLM responses are inherently stochastic, so sometimes the model
might choose to call only one tool, and sometimes might call tools
multiple times.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>msg <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;add three plus four. then multiply by ten&quot;</span>)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, msg, <span class="at">tools =</span> <span class="fu">list</span>(tool1, tool2), <span class="at">output =</span> <span class="st">&quot;tools&quot;</span>)</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co"># first tool/function: add_two_numbers(3, 4)</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="fu">do.call</span>(resp[[<span class="dv">1</span>]]<span class="sc">$</span>name, resp[[<span class="dv">1</span>]]<span class="sc">$</span>arguments) <span class="co"># 7</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="co"># second tool/function: multiply_two_numbers(7, 10)</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a><span class="fu">do.call</span>(resp[[<span class="dv">2</span>]]<span class="sc">$</span>name, resp[[<span class="dv">2</span>]]<span class="sc">$</span>arguments) <span class="co"># 70</span></span></code></pre></div>
</div>
<div id="structured-outputs" class="section level3">
<h3>Structured outputs</h3>
<p>The <code>chat()</code> and <code>generate()</code> functions support
<a href="https://ollama.com/blog/structured-outputs">structured
outputs</a>, making it possible to constrain a model’s output to a
specified format defined by a JSON schema (R list).</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co"># define a JSON schema as a list to constrain a model&#39;s output</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>format <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;object&quot;</span>,</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="at">properties =</span> <span class="fu">list</span>(</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    <span class="at">name =</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;string&quot;</span>),</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>    <span class="at">capital =</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;string&quot;</span>),</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>    <span class="at">languages =</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;array&quot;</span>,</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>                     <span class="at">items =</span> <span class="fu">list</span>(<span class="at">type =</span> <span class="st">&quot;string&quot;</span>)</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>                     )</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>    ),</span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>  <span class="at">required =</span> <span class="fu">list</span>(<span class="st">&quot;name&quot;</span>, <span class="st">&quot;capital&quot;</span>, <span class="st">&quot;languages&quot;</span>)</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>  )</span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a><span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, <span class="st">&quot;tell me about Canada&quot;</span>, <span class="at">output =</span> <span class="st">&quot;structured&quot;</span>, <span class="at">format =</span> format)</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a>msg <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;tell me about Canada&quot;</span>)</span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a><span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, msg, <span class="at">format =</span> format, <span class="at">output =</span> <span class="st">&quot;structured&quot;</span>)</span></code></pre></div>
</div>
<div id="parallel-requests" class="section level3">
<h3>Parallel requests</h3>
<p>For the <code>generate()</code> and <code>chat()</code>
endpoints/functions, you can specify <code>output = &#39;req&#39;</code> in the
function so the functions return <code>httr2_request</code> objects
instead of <code>httr2_response</code> objects.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>prompt <span class="ot">&lt;-</span> <span class="st">&quot;Tell me a 10-word story&quot;</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>req <span class="ot">&lt;-</span> <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, prompt, <span class="at">output =</span> <span class="st">&quot;req&quot;</span>)  <span class="co"># returns a httr2_request object</span></span></code></pre></div>
<p>When you have multiple <code>httr2_request</code> objects in a list,
you can make parallel requests with the
<code>req_perform_parallel</code> function from the <code>httr2</code>
library. See <a href="https://httr2.r-lib.org/reference/req_perform_parallel.html"><code>httr2</code>
documentation</a> for details.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">library</span>(httr2)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>prompt <span class="ot">&lt;-</span> <span class="st">&quot;Tell me a 5-word story&quot;</span></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="co"># create 5 httr2_request objects that generate a response to the same prompt</span></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>reqs <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="cf">function</span>(r) <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, prompt, <span class="at">output =</span> <span class="st">&quot;req&quot;</span>))</span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a><span class="co"># make parallel requests and get response</span></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>resps <span class="ot">&lt;-</span> <span class="fu">req_perform_parallel</span>(reqs)  <span class="co"># list of httr2_request objects</span></span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a><span class="co"># process the responses</span></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a><span class="fu">sapply</span>(resps, resp_process, <span class="st">&quot;text&quot;</span>)  <span class="co"># get responses as text</span></span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a><span class="co"># [1] &quot;She found him in Paris.&quot;         &quot;She found the key upstairs.&quot;</span></span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a><span class="co"># [3] &quot;She found her long-lost sister.&quot; &quot;She found love on Mars.&quot;</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a><span class="co"># [5] &quot;She found the diamond ring.&quot;</span></span></code></pre></div>
<p>Example sentiment analysis with parallel requests with
<code>generate()</code> function</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="fu">library</span>(httr2)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="fu">library</span>(glue)</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="co"># text to classify</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>texts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;I love this product&#39;</span>, <span class="st">&#39;I hate this product&#39;</span>, <span class="st">&#39;I am neutral about this product&#39;</span>)</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co"># create httr2_request objects for each text, using the same system prompt</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>reqs <span class="ot">&lt;-</span> <span class="fu">lapply</span>(texts, <span class="cf">function</span>(text) {</span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>  prompt <span class="ot">&lt;-</span> <span class="fu">glue</span>(<span class="st">&quot;Your only task/role is to evaluate the sentiment of product reviews, and your response should be one of the following:&#39;positive&#39;, &#39;negative&#39;, or &#39;other&#39;. Product review: {text}&quot;</span>)</span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="st">&quot;llama3.1&quot;</span>, prompt, <span class="at">output =</span> <span class="st">&quot;req&quot;</span>)</span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>})</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a><span class="co"># make parallel requests and get response</span></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>resps <span class="ot">&lt;-</span> <span class="fu">req_perform_parallel</span>(reqs)  <span class="co"># list of httr2_request objects</span></span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a><span class="co"># process the responses</span></span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a><span class="fu">sapply</span>(resps, resp_process, <span class="st">&quot;text&quot;</span>)  <span class="co"># get responses as text</span></span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a><span class="co"># [1] &quot;Positive&quot;                            &quot;Negative.&quot;</span></span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a><span class="co"># [3] &quot;&#39;neutral&#39; translates to... &#39;other&#39;.&quot;</span></span></code></pre></div>
<p>Example sentiment analysis with parallel requests with
<code>chat()</code> function</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="fu">library</span>(httr2)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="co"># text to classify</span></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>texts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;I love this product&#39;</span>, <span class="st">&#39;I hate this product&#39;</span>, <span class="st">&#39;I am neutral about this product&#39;</span>)</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="co"># create system prompt</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>chat_history <span class="ot">&lt;-</span> <span class="fu">create_message</span>(<span class="st">&quot;Your only task/role is to evaluate the sentiment of product reviews provided by the user. Your response should simply be &#39;positive&#39;, &#39;negative&#39;, or &#39;other&#39;.&quot;</span>, <span class="st">&quot;system&quot;</span>)</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a><span class="co"># create httr2_request objects for each text, using the same system prompt</span></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a>reqs <span class="ot">&lt;-</span> <span class="fu">lapply</span>(texts, <span class="cf">function</span>(text) {</span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a>  messages <span class="ot">&lt;-</span> <span class="fu">append_message</span>(text, <span class="st">&quot;user&quot;</span>, chat_history)</span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>  <span class="fu">chat</span>(<span class="st">&quot;llama3.1&quot;</span>, messages, <span class="at">output =</span> <span class="st">&quot;req&quot;</span>)</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a>})</span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a><span class="co"># make parallel requests and get response</span></span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>resps <span class="ot">&lt;-</span> <span class="fu">req_perform_parallel</span>(reqs)  <span class="co"># list of httr2_request objects</span></span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a><span class="co"># process the responses</span></span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a><span class="fu">bind_rows</span>(<span class="fu">lapply</span>(resps, resp_process, <span class="st">&quot;df&quot;</span>))  <span class="co"># get responses as dataframes</span></span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a><span class="co"># # A tibble: 3 × 4</span></span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a><span class="co">#   model    role      content  created_at</span></span>
<span id="cb23-23"><a href="#cb23-23" tabindex="-1"></a><span class="co">#   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;</span></span>
<span id="cb23-24"><a href="#cb23-24" tabindex="-1"></a><span class="co"># 1 llama3.1 assistant Positive 2024-08-05T17:54:27.758618Z</span></span>
<span id="cb23-25"><a href="#cb23-25" tabindex="-1"></a><span class="co"># 2 llama3.1 assistant negative 2024-08-05T17:54:27.657525Z</span></span>
<span id="cb23-26"><a href="#cb23-26" tabindex="-1"></a><span class="co"># 3 llama3.1 assistant other    2024-08-05T17:54:27.657067Z</span></span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
